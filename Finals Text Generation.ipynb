{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailã\\xadn': 556, 'deas': 557, 'crãºite': 558, 'na': 559, 'mbã³': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lã¡mh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'cï¿½ta': 2176, 'mï¿½r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n",
      "2690\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = open(r\"C:\\Users\\kjson\\Downloads\\irish-lyrics-eof.txt\").read()\n",
    "\n",
    "#corpus data normalized -> lower, split into string by new line characters\n",
    "c_data = data.lower().split(\"\\n\")\n",
    "\n",
    "#fit the corpus data to toke\n",
    "tokenizer.fit_on_texts(c_data)\n",
    "\n",
    "# Save the tokenizer using pickle\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "#observe that we no longer use OOV instead we use +1\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for line in c_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequences = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequences)\n",
    "        \n",
    "# pad sequences\n",
    "max_sequences_len = max ([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                                         maxlen=max_sequences_len,\n",
    "                                         padding= 'pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictors and label\n",
    "\n",
    "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes= total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "1\n",
      "71\n",
      "6\n",
      "713\n",
      "39\n",
      "1790\n",
      "1791\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "print (xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0   51   12   96 1217   48\n",
      "    2]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (xs[5])\n",
    "print (ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailã\\xadn': 556, 'deas': 557, 'crãºite': 558, 'na': 559, 'mbã³': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lã¡mh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'cï¿½ta': 2176, 'mï¿½r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequences_len-1))\n",
    "model.add(Bidirectional(LSTM(256)))  # Remove return_sequences=True\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 15, 100)           269000    \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 512)              731136    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2690)              1379970   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,380,106\n",
      "Trainable params: 2,380,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 6.6971 - accuracy: 0.0642\n",
      "Epoch 1: loss improved from inf to 6.69708, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 120ms/step - loss: 6.6971 - accuracy: 0.0642\n",
      "Epoch 2/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 6.2497 - accuracy: 0.0754\n",
      "Epoch 2: loss improved from 6.69708 to 6.24973, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 47s 125ms/step - loss: 6.2497 - accuracy: 0.0754\n",
      "Epoch 3/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 5.9841 - accuracy: 0.0851\n",
      "Epoch 3: loss improved from 6.24973 to 5.98411, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 5.9841 - accuracy: 0.0851\n",
      "Epoch 4/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 5.6811 - accuracy: 0.1008\n",
      "Epoch 4: loss improved from 5.98411 to 5.68111, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 131ms/step - loss: 5.6811 - accuracy: 0.1008\n",
      "Epoch 5/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 5.3072 - accuracy: 0.1166\n",
      "Epoch 5: loss improved from 5.68111 to 5.30716, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 57s 151ms/step - loss: 5.3072 - accuracy: 0.1166\n",
      "Epoch 6/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 4.8780 - accuracy: 0.1383\n",
      "Epoch 6: loss improved from 5.30716 to 4.87800, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 58s 154ms/step - loss: 4.8780 - accuracy: 0.1383\n",
      "Epoch 7/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 4.4203 - accuracy: 0.1664\n",
      "Epoch 7: loss improved from 4.87800 to 4.42035, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 56s 148ms/step - loss: 4.4203 - accuracy: 0.1664\n",
      "Epoch 8/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 3.9446 - accuracy: 0.2135\n",
      "Epoch 8: loss improved from 4.42035 to 3.94461, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 3.9446 - accuracy: 0.2135\n",
      "Epoch 9/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 3.4678 - accuracy: 0.2739\n",
      "Epoch 9: loss improved from 3.94461 to 3.46785, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 131ms/step - loss: 3.4678 - accuracy: 0.2739\n",
      "Epoch 10/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 3.0286 - accuracy: 0.3499\n",
      "Epoch 10: loss improved from 3.46785 to 3.02857, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 3.0286 - accuracy: 0.3499\n",
      "Epoch 11/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 2.6346 - accuracy: 0.4259\n",
      "Epoch 11: loss improved from 3.02857 to 2.63461, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 55s 145ms/step - loss: 2.6346 - accuracy: 0.4259\n",
      "Epoch 12/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 2.2962 - accuracy: 0.4956\n",
      "Epoch 12: loss improved from 2.63461 to 2.29621, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 54s 143ms/step - loss: 2.2962 - accuracy: 0.4956\n",
      "Epoch 13/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 2.0281 - accuracy: 0.5461\n",
      "Epoch 13: loss improved from 2.29621 to 2.02812, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 54s 142ms/step - loss: 2.0281 - accuracy: 0.5461\n",
      "Epoch 14/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.7951 - accuracy: 0.6023\n",
      "Epoch 14: loss improved from 2.02812 to 1.79507, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 140ms/step - loss: 1.7951 - accuracy: 0.6023\n",
      "Epoch 15/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.6386\n",
      "Epoch 15: loss improved from 1.79507 to 1.60141, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 59s 156ms/step - loss: 1.6014 - accuracy: 0.6386\n",
      "Epoch 16/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.4328 - accuracy: 0.6761\n",
      "Epoch 16: loss improved from 1.60141 to 1.43284, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 1.4328 - accuracy: 0.6761\n",
      "Epoch 17/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.3096 - accuracy: 0.7082\n",
      "Epoch 17: loss improved from 1.43284 to 1.30956, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 1.3096 - accuracy: 0.7082\n",
      "Epoch 18/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.2075 - accuracy: 0.7299\n",
      "Epoch 18: loss improved from 1.30956 to 1.20750, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 126ms/step - loss: 1.2075 - accuracy: 0.7299\n",
      "Epoch 19/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.0964 - accuracy: 0.7545\n",
      "Epoch 19: loss improved from 1.20750 to 1.09638, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 140ms/step - loss: 1.0964 - accuracy: 0.7545\n",
      "Epoch 20/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.7741\n",
      "Epoch 20: loss improved from 1.09638 to 1.00917, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 58s 155ms/step - loss: 1.0092 - accuracy: 0.7741\n",
      "Epoch 21/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.7840\n",
      "Epoch 21: loss improved from 1.00917 to 0.96571, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.9657 - accuracy: 0.7840\n",
      "Epoch 22/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.7942\n",
      "Epoch 22: loss improved from 0.96571 to 0.90337, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 55s 145ms/step - loss: 0.9034 - accuracy: 0.7942\n",
      "Epoch 23/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.8619 - accuracy: 0.8050\n",
      "Epoch 23: loss improved from 0.90337 to 0.86194, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 134ms/step - loss: 0.8619 - accuracy: 0.8050\n",
      "Epoch 24/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.8104\n",
      "Epoch 24: loss improved from 0.86194 to 0.82916, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.8292 - accuracy: 0.8104\n",
      "Epoch 25/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.8172\n",
      "Epoch 25: loss improved from 0.82916 to 0.79519, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 139ms/step - loss: 0.7952 - accuracy: 0.8172\n",
      "Epoch 26/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.8211\n",
      "Epoch 26: loss improved from 0.79519 to 0.76682, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 133ms/step - loss: 0.7668 - accuracy: 0.8211\n",
      "Epoch 27/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7528 - accuracy: 0.8244\n",
      "Epoch 27: loss improved from 0.76682 to 0.75285, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.7528 - accuracy: 0.8244\n",
      "Epoch 28/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7202 - accuracy: 0.8300\n",
      "Epoch 28: loss improved from 0.75285 to 0.72021, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 0.7202 - accuracy: 0.8300\n",
      "Epoch 29/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.8314\n",
      "Epoch 29: loss improved from 0.72021 to 0.71235, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.7123 - accuracy: 0.8314\n",
      "Epoch 30/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.8356\n",
      "Epoch 30: loss improved from 0.71235 to 0.69023, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 133ms/step - loss: 0.6902 - accuracy: 0.8356\n",
      "Epoch 31/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.8384\n",
      "Epoch 31: loss improved from 0.69023 to 0.68150, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 55s 147ms/step - loss: 0.6815 - accuracy: 0.8384\n",
      "Epoch 32/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.8399\n",
      "Epoch 32: loss improved from 0.68150 to 0.66802, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.6680 - accuracy: 0.8399\n",
      "Epoch 33/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.8403\n",
      "Epoch 33: loss improved from 0.66802 to 0.65641, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 56s 150ms/step - loss: 0.6564 - accuracy: 0.8403\n",
      "Epoch 34/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.8398\n",
      "Epoch 34: loss improved from 0.65641 to 0.65334, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.6533 - accuracy: 0.8398\n",
      "Epoch 35/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.8420\n",
      "Epoch 35: loss improved from 0.65334 to 0.64418, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.6442 - accuracy: 0.8420\n",
      "Epoch 36/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.8408\n",
      "Epoch 36: loss did not improve from 0.64418\n",
      "377/377 [==============================] - 56s 148ms/step - loss: 0.6447 - accuracy: 0.8408\n",
      "Epoch 37/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.8425\n",
      "Epoch 37: loss improved from 0.64418 to 0.63007, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 139ms/step - loss: 0.6301 - accuracy: 0.8425\n",
      "Epoch 38/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.8413\n",
      "Epoch 38: loss did not improve from 0.63007\n",
      "377/377 [==============================] - 51s 135ms/step - loss: 0.6333 - accuracy: 0.8413\n",
      "Epoch 39/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.8450\n",
      "Epoch 39: loss improved from 0.63007 to 0.61652, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.6165 - accuracy: 0.8450\n",
      "Epoch 40/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.8449\n",
      "Epoch 40: loss improved from 0.61652 to 0.61552, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.6155 - accuracy: 0.8449\n",
      "Epoch 41/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.8442\n",
      "Epoch 41: loss improved from 0.61552 to 0.61183, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 140ms/step - loss: 0.6118 - accuracy: 0.8442\n",
      "Epoch 42/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.8447\n",
      "Epoch 42: loss improved from 0.61183 to 0.60347, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 135ms/step - loss: 0.6035 - accuracy: 0.8447\n",
      "Epoch 43/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.8428\n",
      "Epoch 43: loss did not improve from 0.60347\n",
      "377/377 [==============================] - 52s 139ms/step - loss: 0.6122 - accuracy: 0.8428\n",
      "Epoch 44/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.8479\n",
      "Epoch 44: loss improved from 0.60347 to 0.59740, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.5974 - accuracy: 0.8479\n",
      "Epoch 45/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.8462\n",
      "Epoch 45: loss improved from 0.59740 to 0.59425, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 135ms/step - loss: 0.5942 - accuracy: 0.8462\n",
      "Epoch 46/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5885 - accuracy: 0.8476\n",
      "Epoch 46: loss improved from 0.59425 to 0.58849, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 140ms/step - loss: 0.5885 - accuracy: 0.8476\n",
      "Epoch 47/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.8455\n",
      "Epoch 47: loss did not improve from 0.58849\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.5923 - accuracy: 0.8455\n",
      "Epoch 48/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.8491\n",
      "Epoch 48: loss improved from 0.58849 to 0.58044, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 135ms/step - loss: 0.5804 - accuracy: 0.8491\n",
      "Epoch 49/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8491\n",
      "Epoch 49: loss did not improve from 0.58044\n",
      "377/377 [==============================] - 50s 133ms/step - loss: 0.5817 - accuracy: 0.8491\n",
      "Epoch 50/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.8463\n",
      "Epoch 50: loss improved from 0.58044 to 0.57977, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5798 - accuracy: 0.8463\n",
      "Epoch 51/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.8486\n",
      "Epoch 51: loss improved from 0.57977 to 0.57974, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5797 - accuracy: 0.8486\n",
      "Epoch 52/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8480\n",
      "Epoch 52: loss improved from 0.57974 to 0.57185, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5719 - accuracy: 0.8480\n",
      "Epoch 53/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.8487\n",
      "Epoch 53: loss improved from 0.57185 to 0.56901, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5690 - accuracy: 0.8487\n",
      "Epoch 54/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.8501\n",
      "Epoch 54: loss improved from 0.56901 to 0.56251, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 138ms/step - loss: 0.5625 - accuracy: 0.8501\n",
      "Epoch 55/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.8491\n",
      "Epoch 55: loss did not improve from 0.56251\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5644 - accuracy: 0.8491\n",
      "Epoch 56/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.8510\n",
      "Epoch 56: loss did not improve from 0.56251\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.5626 - accuracy: 0.8510\n",
      "Epoch 57/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.8503\n",
      "Epoch 57: loss did not improve from 0.56251\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.5635 - accuracy: 0.8503\n",
      "Epoch 58/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8487\n",
      "Epoch 58: loss did not improve from 0.56251\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5676 - accuracy: 0.8487\n",
      "Epoch 59/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.8493\n",
      "Epoch 59: loss improved from 0.56251 to 0.56028, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 126ms/step - loss: 0.5603 - accuracy: 0.8493\n",
      "Epoch 60/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.8499\n",
      "Epoch 60: loss improved from 0.56028 to 0.55743, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5574 - accuracy: 0.8499\n",
      "Epoch 61/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8500\n",
      "Epoch 61: loss improved from 0.55743 to 0.55022, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 126ms/step - loss: 0.5502 - accuracy: 0.8500\n",
      "Epoch 62/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.8496\n",
      "Epoch 62: loss improved from 0.55022 to 0.54990, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 126ms/step - loss: 0.5499 - accuracy: 0.8496\n",
      "Epoch 63/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.8521\n",
      "Epoch 63: loss did not improve from 0.54990\n",
      "377/377 [==============================] - 56s 149ms/step - loss: 0.5515 - accuracy: 0.8521\n",
      "Epoch 64/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.8525\n",
      "Epoch 64: loss did not improve from 0.54990\n",
      "377/377 [==============================] - 52s 139ms/step - loss: 0.5506 - accuracy: 0.8525\n",
      "Epoch 65/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.8526\n",
      "Epoch 65: loss improved from 0.54990 to 0.54354, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 138ms/step - loss: 0.5435 - accuracy: 0.8526\n",
      "Epoch 66/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.8516\n",
      "Epoch 66: loss improved from 0.54354 to 0.53861, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 139ms/step - loss: 0.5386 - accuracy: 0.8516\n",
      "Epoch 67/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8522\n",
      "Epoch 67: loss did not improve from 0.53861\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 0.5424 - accuracy: 0.8522\n",
      "Epoch 68/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.8521\n",
      "Epoch 68: loss did not improve from 0.53861\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5396 - accuracy: 0.8521\n",
      "Epoch 69/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.8523\n",
      "Epoch 69: loss improved from 0.53861 to 0.53402, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5340 - accuracy: 0.8523\n",
      "Epoch 70/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8498\n",
      "Epoch 70: loss did not improve from 0.53402\n",
      "377/377 [==============================] - 47s 126ms/step - loss: 0.5418 - accuracy: 0.8498\n",
      "Epoch 71/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.8518\n",
      "Epoch 71: loss did not improve from 0.53402\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5390 - accuracy: 0.8518\n",
      "Epoch 72/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8519\n",
      "Epoch 72: loss did not improve from 0.53402\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5350 - accuracy: 0.8519\n",
      "Epoch 73/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8531\n",
      "Epoch 73: loss improved from 0.53402 to 0.53111, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 47s 126ms/step - loss: 0.5311 - accuracy: 0.8531\n",
      "Epoch 74/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.8482\n",
      "Epoch 74: loss did not improve from 0.53111\n",
      "377/377 [==============================] - 47s 126ms/step - loss: 0.5356 - accuracy: 0.8482\n",
      "Epoch 75/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8519\n",
      "Epoch 75: loss did not improve from 0.53111\n",
      "377/377 [==============================] - 47s 125ms/step - loss: 0.5347 - accuracy: 0.8519\n",
      "Epoch 76/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.8503\n",
      "Epoch 76: loss did not improve from 0.53111\n",
      "377/377 [==============================] - 52s 139ms/step - loss: 0.5337 - accuracy: 0.8503\n",
      "Epoch 77/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.8529\n",
      "Epoch 77: loss improved from 0.53111 to 0.52914, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 0.5291 - accuracy: 0.8529\n",
      "Epoch 78/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.8540\n",
      "Epoch 78: loss improved from 0.52914 to 0.52271, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5227 - accuracy: 0.8540\n",
      "Epoch 79/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8537\n",
      "Epoch 79: loss did not improve from 0.52271\n",
      "377/377 [==============================] - 47s 126ms/step - loss: 0.5299 - accuracy: 0.8537\n",
      "Epoch 80/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.8530\n",
      "Epoch 80: loss did not improve from 0.52271\n",
      "377/377 [==============================] - 47s 126ms/step - loss: 0.5241 - accuracy: 0.8530\n",
      "Epoch 81/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8502\n",
      "Epoch 81: loss did not improve from 0.52271\n",
      "377/377 [==============================] - 47s 125ms/step - loss: 0.5278 - accuracy: 0.8502\n",
      "Epoch 82/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8511\n",
      "Epoch 82: loss did not improve from 0.52271\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5257 - accuracy: 0.8511\n",
      "Epoch 83/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.8522\n",
      "Epoch 83: loss improved from 0.52271 to 0.51779, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.5178 - accuracy: 0.8522\n",
      "Epoch 84/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8543\n",
      "Epoch 84: loss did not improve from 0.51779\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.5185 - accuracy: 0.8543\n",
      "Epoch 85/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5187 - accuracy: 0.8536\n",
      "Epoch 85: loss did not improve from 0.51779\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.5187 - accuracy: 0.8536\n",
      "Epoch 86/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.8515\n",
      "Epoch 86: loss did not improve from 0.51779\n",
      "377/377 [==============================] - 51s 134ms/step - loss: 0.5211 - accuracy: 0.8515\n",
      "Epoch 87/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8516\n",
      "Epoch 87: loss improved from 0.51779 to 0.51602, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 133ms/step - loss: 0.5160 - accuracy: 0.8516\n",
      "Epoch 88/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.8530\n",
      "Epoch 88: loss did not improve from 0.51602\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5175 - accuracy: 0.8530\n",
      "Epoch 89/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8510\n",
      "Epoch 89: loss did not improve from 0.51602\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5203 - accuracy: 0.8510\n",
      "Epoch 90/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.8531\n",
      "Epoch 90: loss improved from 0.51602 to 0.51339, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.5134 - accuracy: 0.8531\n",
      "Epoch 91/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.8534\n",
      "Epoch 91: loss did not improve from 0.51339\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5156 - accuracy: 0.8534\n",
      "Epoch 92/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8521\n",
      "Epoch 92: loss improved from 0.51339 to 0.51237, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5124 - accuracy: 0.8521\n",
      "Epoch 93/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8521\n",
      "Epoch 93: loss did not improve from 0.51237\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5136 - accuracy: 0.8521\n",
      "Epoch 94/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.8511\n",
      "Epoch 94: loss improved from 0.51237 to 0.51142, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.5114 - accuracy: 0.8511\n",
      "Epoch 95/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8545\n",
      "Epoch 95: loss improved from 0.51142 to 0.50429, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5043 - accuracy: 0.8545\n",
      "Epoch 96/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.8534\n",
      "Epoch 96: loss did not improve from 0.50429\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5056 - accuracy: 0.8534\n",
      "Epoch 97/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8533\n",
      "Epoch 97: loss improved from 0.50429 to 0.50426, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 129ms/step - loss: 0.5043 - accuracy: 0.8533\n",
      "Epoch 98/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.8526\n",
      "Epoch 98: loss did not improve from 0.50426\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5130 - accuracy: 0.8526\n",
      "Epoch 99/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8532\n",
      "Epoch 99: loss did not improve from 0.50426\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5124 - accuracy: 0.8532\n",
      "Epoch 100/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.8527\n",
      "Epoch 100: loss did not improve from 0.50426\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5045 - accuracy: 0.8527\n",
      "Epoch 101/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8520\n",
      "Epoch 101: loss did not improve from 0.50426\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5059 - accuracy: 0.8520\n",
      "Epoch 102/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.8545\n",
      "Epoch 102: loss improved from 0.50426 to 0.50289, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5029 - accuracy: 0.8545\n",
      "Epoch 103/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.8534\n",
      "Epoch 103: loss did not improve from 0.50289\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.5034 - accuracy: 0.8534\n",
      "Epoch 104/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.8538\n",
      "Epoch 104: loss did not improve from 0.50289\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5044 - accuracy: 0.8538\n",
      "Epoch 105/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.8547\n",
      "Epoch 105: loss improved from 0.50289 to 0.49880, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.4988 - accuracy: 0.8547\n",
      "Epoch 106/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.8552\n",
      "Epoch 106: loss did not improve from 0.49880\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.5038 - accuracy: 0.8552\n",
      "Epoch 107/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8526\n",
      "Epoch 107: loss did not improve from 0.49880\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.5019 - accuracy: 0.8526\n",
      "Epoch 108/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8529\n",
      "Epoch 108: loss did not improve from 0.49880\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.5037 - accuracy: 0.8529\n",
      "Epoch 109/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.8556\n",
      "Epoch 109: loss improved from 0.49880 to 0.49826, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.4983 - accuracy: 0.8556\n",
      "Epoch 110/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.8531\n",
      "Epoch 110: loss did not improve from 0.49826\n",
      "377/377 [==============================] - 48s 127ms/step - loss: 0.5010 - accuracy: 0.8531\n",
      "Epoch 111/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.8545\n",
      "Epoch 111: loss improved from 0.49826 to 0.49775, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 48s 128ms/step - loss: 0.4978 - accuracy: 0.8545\n",
      "Epoch 112/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4961 - accuracy: 0.8560\n",
      "Epoch 112: loss improved from 0.49775 to 0.49612, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.4961 - accuracy: 0.8560\n",
      "Epoch 113/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8533\n",
      "Epoch 113: loss did not improve from 0.49612\n",
      "377/377 [==============================] - 56s 149ms/step - loss: 0.4989 - accuracy: 0.8533\n",
      "Epoch 114/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.8536\n",
      "Epoch 114: loss did not improve from 0.49612\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.4972 - accuracy: 0.8536\n",
      "Epoch 115/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.8555\n",
      "Epoch 115: loss improved from 0.49612 to 0.49237, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 53s 142ms/step - loss: 0.4924 - accuracy: 0.8555\n",
      "Epoch 116/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.8539\n",
      "Epoch 116: loss did not improve from 0.49237\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.4959 - accuracy: 0.8539\n",
      "Epoch 117/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8538\n",
      "Epoch 117: loss did not improve from 0.49237\n",
      "377/377 [==============================] - 53s 141ms/step - loss: 0.4936 - accuracy: 0.8538\n",
      "Epoch 118/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.8528\n",
      "Epoch 118: loss did not improve from 0.49237\n",
      "377/377 [==============================] - 53s 140ms/step - loss: 0.4976 - accuracy: 0.8528\n",
      "Epoch 119/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8526\n",
      "Epoch 119: loss did not improve from 0.49237\n",
      "377/377 [==============================] - 52s 138ms/step - loss: 0.4977 - accuracy: 0.8526\n",
      "Epoch 120/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8531\n",
      "Epoch 120: loss improved from 0.49237 to 0.49162, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 51s 136ms/step - loss: 0.4916 - accuracy: 0.8531\n",
      "Epoch 121/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.8558\n",
      "Epoch 121: loss improved from 0.49162 to 0.48775, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 52s 137ms/step - loss: 0.4877 - accuracy: 0.8558\n",
      "Epoch 122/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.8522\n",
      "Epoch 122: loss did not improve from 0.48775\n",
      "377/377 [==============================] - 50s 134ms/step - loss: 0.4934 - accuracy: 0.8522\n",
      "Epoch 123/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.8545\n",
      "Epoch 123: loss did not improve from 0.48775\n",
      "377/377 [==============================] - 49s 129ms/step - loss: 0.4945 - accuracy: 0.8545\n",
      "Epoch 124/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.8535\n",
      "Epoch 124: loss did not improve from 0.48775\n",
      "377/377 [==============================] - 50s 133ms/step - loss: 0.4930 - accuracy: 0.8535\n",
      "Epoch 125/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8555\n",
      "Epoch 125: loss improved from 0.48775 to 0.48475, saving model to model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 134ms/step - loss: 0.4848 - accuracy: 0.8555\n",
      "Epoch 126/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.8549\n",
      "Epoch 126: loss did not improve from 0.48475\n",
      "377/377 [==============================] - 56s 148ms/step - loss: 0.4913 - accuracy: 0.8549\n",
      "Epoch 127/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.8550\n",
      "Epoch 127: loss did not improve from 0.48475\n",
      "377/377 [==============================] - 54s 142ms/step - loss: 0.4861 - accuracy: 0.8550\n",
      "Epoch 128/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.8543\n",
      "Epoch 128: loss did not improve from 0.48475\n",
      "377/377 [==============================] - 58s 154ms/step - loss: 0.4909 - accuracy: 0.8543\n",
      "Epoch 129/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.8540\n",
      "Epoch 129: loss did not improve from 0.48475\n",
      "377/377 [==============================] - 55s 147ms/step - loss: 0.4884 - accuracy: 0.8540\n",
      "Epoch 130/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.8520Restoring model weights from the end of the best epoch: 125.\n",
      "\n",
      "Epoch 130: loss did not improve from 0.48475\n",
      "377/377 [==============================] - 55s 146ms/step - loss: 0.4926 - accuracy: 0.8520\n",
      "Epoch 130: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Define the EarlyStopping and ModelCheckpoint callbacks\n",
    "earlystop = EarlyStopping(monitor='loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"model_checkpoint.h5\",\n",
    "                             monitor=\"loss\",\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode=\"min\")\n",
    "\n",
    "# Train the model with the EarlyStopping and ModelCheckpoint callbacks\n",
    "history = model.fit(xs, ys, epochs=1000, verbose=1, callbacks=[earlystop, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history,string):\n",
    "    plt.plot (history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "I've got a good feeling about this fell on your lip and they easy down the girl of the wind majestic shannon shannon they trudged side down\n"
     ]
    }
   ],
   "source": [
    "seed_text= \"I've got a good feeling about this\"\n",
    "next_words = 20\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequences_len - 1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 15, 100)           269000    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 256)               365568    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2690)              691330    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325,898\n",
      "Trainable params: 1,325,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 6.6876 - accuracy: 0.0639\n",
      "Epoch 1: loss improved from inf to 6.68759, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 34s 83ms/step - loss: 6.6876 - accuracy: 0.0639\n",
      "Epoch 2/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 6.2746 - accuracy: 0.0770\n",
      "Epoch 2: loss improved from 6.68759 to 6.27420, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 32s 85ms/step - loss: 6.2742 - accuracy: 0.0769\n",
      "Epoch 3/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 6.0700 - accuracy: 0.0842\n",
      "Epoch 3: loss improved from 6.27420 to 6.07094, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 33s 87ms/step - loss: 6.0709 - accuracy: 0.0842\n",
      "Epoch 4/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 5.8560 - accuracy: 0.0940\n",
      "Epoch 4: loss improved from 6.07094 to 5.85649, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 33s 87ms/step - loss: 5.8565 - accuracy: 0.0940\n",
      "Epoch 5/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 5.6159 - accuracy: 0.1042\n",
      "Epoch 5: loss improved from 5.85649 to 5.61528, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 34s 91ms/step - loss: 5.6153 - accuracy: 0.1043\n",
      "Epoch 6/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 5.3405 - accuracy: 0.1146\n",
      "Epoch 6: loss improved from 5.61528 to 5.34054, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 34s 91ms/step - loss: 5.3405 - accuracy: 0.1146\n",
      "Epoch 7/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 5.0396 - accuracy: 0.1281\n",
      "Epoch 7: loss improved from 5.34054 to 5.04018, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 32s 85ms/step - loss: 5.0402 - accuracy: 0.1280\n",
      "Epoch 8/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 4.7099 - accuracy: 0.1443\n",
      "Epoch 8: loss improved from 5.04018 to 4.70986, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 34s 91ms/step - loss: 4.7099 - accuracy: 0.1443\n",
      "Epoch 9/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 4.3787 - accuracy: 0.1762\n",
      "Epoch 9: loss improved from 4.70986 to 4.37864, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 34s 90ms/step - loss: 4.3786 - accuracy: 0.1762\n",
      "Epoch 10/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 4.0441 - accuracy: 0.2084\n",
      "Epoch 10: loss improved from 4.37864 to 4.04387, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 31s 82ms/step - loss: 4.0439 - accuracy: 0.2084\n",
      "Epoch 11/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 3.7237 - accuracy: 0.2562\n",
      "Epoch 11: loss improved from 4.04387 to 3.72303, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 3.7230 - accuracy: 0.2564\n",
      "Epoch 12/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 3.4153 - accuracy: 0.3089\n",
      "Epoch 12: loss improved from 3.72303 to 3.41516, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 3.4152 - accuracy: 0.3089\n",
      "Epoch 13/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 3.1367 - accuracy: 0.3574\n",
      "Epoch 13: loss improved from 3.41516 to 3.13643, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 3.1364 - accuracy: 0.3575\n",
      "Epoch 14/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.8729 - accuracy: 0.4120\n",
      "Epoch 14: loss improved from 3.13643 to 2.87315, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 29s 78ms/step - loss: 2.8732 - accuracy: 0.4120\n",
      "Epoch 15/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.6274 - accuracy: 0.4618\n",
      "Epoch 15: loss improved from 2.87315 to 2.62774, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 2.6277 - accuracy: 0.4616\n",
      "Epoch 16/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.4136 - accuracy: 0.5088\n",
      "Epoch 16: loss improved from 2.62774 to 2.41388, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 2.4139 - accuracy: 0.5088\n",
      "Epoch 17/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.2105 - accuracy: 0.5489\n",
      "Epoch 17: loss improved from 2.41388 to 2.21114, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 2.2111 - accuracy: 0.5488\n",
      "Epoch 18/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.0311 - accuracy: 0.5844\n",
      "Epoch 18: loss improved from 2.21114 to 2.03098, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 2.0310 - accuracy: 0.5845\n",
      "Epoch 19/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.8764 - accuracy: 0.6174\n",
      "Epoch 19: loss improved from 2.03098 to 1.87646, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 80ms/step - loss: 1.8765 - accuracy: 0.6173\n",
      "Epoch 20/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.7249 - accuracy: 0.6486\n",
      "Epoch 20: loss improved from 1.87646 to 1.72554, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 1.7255 - accuracy: 0.6484\n",
      "Epoch 21/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.5985 - accuracy: 0.6774\n",
      "Epoch 21: loss improved from 1.72554 to 1.59849, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 80ms/step - loss: 1.5985 - accuracy: 0.6774\n",
      "Epoch 22/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.4886 - accuracy: 0.6981\n",
      "Epoch 22: loss improved from 1.59849 to 1.48827, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 1.4883 - accuracy: 0.6982\n",
      "Epoch 23/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.3819 - accuracy: 0.7183\n",
      "Epoch 23: loss improved from 1.48827 to 1.38208, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 1.3821 - accuracy: 0.7183\n",
      "Epoch 24/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.2960 - accuracy: 0.7360\n",
      "Epoch 24: loss improved from 1.38208 to 1.29625, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 29s 78ms/step - loss: 1.2963 - accuracy: 0.7359\n",
      "Epoch 25/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.2126 - accuracy: 0.7473\n",
      "Epoch 25: loss improved from 1.29625 to 1.21250, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 29s 78ms/step - loss: 1.2125 - accuracy: 0.7473\n",
      "Epoch 26/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.1291 - accuracy: 0.7652\n",
      "Epoch 26: loss improved from 1.21250 to 1.12926, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 1.1293 - accuracy: 0.7652\n",
      "Epoch 27/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.0793 - accuracy: 0.7766\n",
      "Epoch 27: loss improved from 1.12926 to 1.07932, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 1.0793 - accuracy: 0.7765\n",
      "Epoch 28/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.0209 - accuracy: 0.7872\n",
      "Epoch 28: loss improved from 1.07932 to 1.02052, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 1.0205 - accuracy: 0.7873\n",
      "Epoch 29/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.7975\n",
      "Epoch 29: loss improved from 1.02052 to 0.96057, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 33s 88ms/step - loss: 0.9606 - accuracy: 0.7975\n",
      "Epoch 30/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.8053\n",
      "Epoch 30: loss improved from 0.96057 to 0.91688, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 31s 82ms/step - loss: 0.9169 - accuracy: 0.8054\n",
      "Epoch 31/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.8770 - accuracy: 0.8101\n",
      "Epoch 31: loss improved from 0.91688 to 0.87701, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.8770 - accuracy: 0.8101\n",
      "Epoch 32/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.8448 - accuracy: 0.8140\n",
      "Epoch 32: loss improved from 0.87701 to 0.84484, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.8448 - accuracy: 0.8139\n",
      "Epoch 33/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.8157 - accuracy: 0.8209\n",
      "Epoch 33: loss improved from 0.84484 to 0.81543, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.8154 - accuracy: 0.8210\n",
      "Epoch 34/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7831 - accuracy: 0.8269\n",
      "Epoch 34: loss improved from 0.81543 to 0.78333, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 0.7833 - accuracy: 0.8267\n",
      "Epoch 35/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7570 - accuracy: 0.8281\n",
      "Epoch 35: loss improved from 0.78333 to 0.75669, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 0.7567 - accuracy: 0.8282\n",
      "Epoch 36/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7324 - accuracy: 0.8334\n",
      "Epoch 36: loss improved from 0.75669 to 0.73228, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.7323 - accuracy: 0.8334\n",
      "Epoch 37/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7125 - accuracy: 0.8384\n",
      "Epoch 37: loss improved from 0.73228 to 0.71256, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.7126 - accuracy: 0.8384\n",
      "Epoch 38/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.8382\n",
      "Epoch 38: loss improved from 0.71256 to 0.69175, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6917 - accuracy: 0.8382\n",
      "Epoch 39/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.8391\n",
      "Epoch 39: loss improved from 0.69175 to 0.68059, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6806 - accuracy: 0.8391\n",
      "Epoch 40/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.8429\n",
      "Epoch 40: loss improved from 0.68059 to 0.66221, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6622 - accuracy: 0.8428\n",
      "Epoch 41/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.8447\n",
      "Epoch 41: loss improved from 0.66221 to 0.65032, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6503 - accuracy: 0.8447\n",
      "Epoch 42/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.8425\n",
      "Epoch 42: loss improved from 0.65032 to 0.64393, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6439 - accuracy: 0.8426\n",
      "Epoch 43/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6262 - accuracy: 0.8455\n",
      "Epoch 43: loss improved from 0.64393 to 0.62647, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6265 - accuracy: 0.8454\n",
      "Epoch 44/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6189 - accuracy: 0.8464\n",
      "Epoch 44: loss improved from 0.62647 to 0.61917, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6192 - accuracy: 0.8462\n",
      "Epoch 45/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6093 - accuracy: 0.8467\n",
      "Epoch 45: loss improved from 0.61917 to 0.60951, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6095 - accuracy: 0.8467\n",
      "Epoch 46/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.8476\n",
      "Epoch 46: loss improved from 0.60951 to 0.60010, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 80ms/step - loss: 0.6001 - accuracy: 0.8476\n",
      "Epoch 47/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.8497\n",
      "Epoch 47: loss did not improve from 0.60010\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.6002 - accuracy: 0.8497\n",
      "Epoch 48/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5867 - accuracy: 0.8505\n",
      "Epoch 48: loss improved from 0.60010 to 0.58704, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5870 - accuracy: 0.8504\n",
      "Epoch 49/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5847 - accuracy: 0.8501\n",
      "Epoch 49: loss improved from 0.58704 to 0.58476, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5848 - accuracy: 0.8501\n",
      "Epoch 50/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.8501\n",
      "Epoch 50: loss improved from 0.58476 to 0.57671, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 80ms/step - loss: 0.5767 - accuracy: 0.8501\n",
      "Epoch 51/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5691 - accuracy: 0.8529\n",
      "Epoch 51: loss improved from 0.57671 to 0.57008, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5701 - accuracy: 0.8526\n",
      "Epoch 52/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5732 - accuracy: 0.8505\n",
      "Epoch 52: loss did not improve from 0.57008\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5729 - accuracy: 0.8506\n",
      "Epoch 53/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5665 - accuracy: 0.8521\n",
      "Epoch 53: loss improved from 0.57008 to 0.56700, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 80ms/step - loss: 0.5670 - accuracy: 0.8520\n",
      "Epoch 54/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.8508\n",
      "Epoch 54: loss did not improve from 0.56700\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5713 - accuracy: 0.8506\n",
      "Epoch 55/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.8529\n",
      "Epoch 55: loss improved from 0.56700 to 0.55919, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5592 - accuracy: 0.8529\n",
      "Epoch 56/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.8526\n",
      "Epoch 56: loss did not improve from 0.55919\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5639 - accuracy: 0.8526\n",
      "Epoch 57/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5569 - accuracy: 0.8511\n",
      "Epoch 57: loss improved from 0.55919 to 0.55666, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5567 - accuracy: 0.8512\n",
      "Epoch 58/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.8526\n",
      "Epoch 58: loss improved from 0.55666 to 0.55462, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5546 - accuracy: 0.8524\n",
      "Epoch 59/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.8497\n",
      "Epoch 59: loss improved from 0.55462 to 0.55400, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5540 - accuracy: 0.8497\n",
      "Epoch 60/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.8521\n",
      "Epoch 60: loss improved from 0.55400 to 0.55328, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5533 - accuracy: 0.8522\n",
      "Epoch 61/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.8541\n",
      "Epoch 61: loss improved from 0.55328 to 0.54131, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5413 - accuracy: 0.8540\n",
      "Epoch 62/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.8536\n",
      "Epoch 62: loss improved from 0.54131 to 0.53976, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5398 - accuracy: 0.8536\n",
      "Epoch 63/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5389 - accuracy: 0.8521\n",
      "Epoch 63: loss improved from 0.53976 to 0.53896, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5390 - accuracy: 0.8521\n",
      "Epoch 64/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.8537\n",
      "Epoch 64: loss did not improve from 0.53896\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5402 - accuracy: 0.8535\n",
      "Epoch 65/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.8544\n",
      "Epoch 65: loss improved from 0.53896 to 0.53149, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5315 - accuracy: 0.8545\n",
      "Epoch 66/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8535\n",
      "Epoch 66: loss did not improve from 0.53149\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 0.5326 - accuracy: 0.8535\n",
      "Epoch 67/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.8535\n",
      "Epoch 67: loss improved from 0.53149 to 0.53078, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 35s 92ms/step - loss: 0.5308 - accuracy: 0.8535\n",
      "Epoch 68/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8538\n",
      "Epoch 68: loss improved from 0.53078 to 0.52805, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5281 - accuracy: 0.8538\n",
      "Epoch 69/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.8530\n",
      "Epoch 69: loss improved from 0.52805 to 0.52520, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5252 - accuracy: 0.8530\n",
      "Epoch 70/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.8530\n",
      "Epoch 70: loss did not improve from 0.52520\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5291 - accuracy: 0.8530\n",
      "Epoch 71/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.8543\n",
      "Epoch 71: loss did not improve from 0.52520\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5314 - accuracy: 0.8543\n",
      "Epoch 72/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8535\n",
      "Epoch 72: loss improved from 0.52520 to 0.52487, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5249 - accuracy: 0.8535\n",
      "Epoch 73/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.8534\n",
      "Epoch 73: loss did not improve from 0.52487\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 0.5250 - accuracy: 0.8534\n",
      "Epoch 74/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.8530\n",
      "Epoch 74: loss did not improve from 0.52487\n",
      "377/377 [==============================] - 50s 131ms/step - loss: 0.5270 - accuracy: 0.8530\n",
      "Epoch 75/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8542\n",
      "Epoch 75: loss improved from 0.52487 to 0.52013, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 50s 132ms/step - loss: 0.5201 - accuracy: 0.8542\n",
      "Epoch 76/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8526\n",
      "Epoch 76: loss did not improve from 0.52013\n",
      "377/377 [==============================] - 49s 130ms/step - loss: 0.5232 - accuracy: 0.8526\n",
      "Epoch 77/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8551\n",
      "Epoch 77: loss did not improve from 0.52013\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5216 - accuracy: 0.8551\n",
      "Epoch 78/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8524\n",
      "Epoch 78: loss improved from 0.52013 to 0.51357, saving model to lstm_model_checkpoint.h5\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5136 - accuracy: 0.8524\n",
      "Epoch 79/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.8528\n",
      "Epoch 79: loss did not improve from 0.51357\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5268 - accuracy: 0.8528\n",
      "Epoch 80/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.8540\n",
      "Epoch 80: loss did not improve from 0.51357\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5207 - accuracy: 0.8540\n",
      "Epoch 81/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8555\n",
      "Epoch 81: loss did not improve from 0.51357\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5182 - accuracy: 0.8555\n",
      "Epoch 82/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8535\n",
      "Epoch 82: loss did not improve from 0.51357\n",
      "377/377 [==============================] - 50s 131ms/step - loss: 0.5144 - accuracy: 0.8535\n",
      "Epoch 83/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8546Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "Epoch 83: loss did not improve from 0.51357\n",
      "377/377 [==============================] - 49s 131ms/step - loss: 0.5138 - accuracy: 0.8546\n",
      "Epoch 83: early stopping\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model \n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(total_words, 100, input_length=max_sequences_len-1))\n",
    "lstm_model.add(LSTM(256))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Define the EarlyStopping and ModelCheckpoint callbacks\n",
    "earlystop = EarlyStopping(monitor='loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"lstm_model_checkpoint.h5\",\n",
    "                             monitor=\"loss\",\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode=\"min\")\n",
    "\n",
    "# Train the model with the EarlyStopping and ModelCheckpoint callbacks\n",
    "lstm_history = lstm_model.fit(xs, ys, epochs=1000, verbose=1, callbacks=[earlystop, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(lstm_history,string):\n",
    "    plt.plot (lstm_history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(lstm_history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(lstm_history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "I've got a good feeling about this more too more more on young and young away oer the dim weeping dawn turning grey there and more ye\n"
     ]
    }
   ],
   "source": [
    "seed_text= \"I've got a good feeling about this\"\n",
    "next_words = 20\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequences_len - 1, padding='pre')\n",
    "    predicted = np.argmax(lstm_model.predict(token_list), axis=1)\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 15, 100)           269000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 256)               274944    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2690)              691330    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,235,274\n",
      "Trainable params: 1,235,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 6.7299 - accuracy: 0.0687\n",
      "Epoch 1: loss improved from inf to 6.73025, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 36s 78ms/step - loss: 6.7302 - accuracy: 0.0687\n",
      "Epoch 2/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 6.1374 - accuracy: 0.0812\n",
      "Epoch 2: loss improved from 6.73025 to 6.13739, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 6.1374 - accuracy: 0.0812\n",
      "Epoch 3/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 5.7924 - accuracy: 0.1009\n",
      "Epoch 3: loss improved from 6.13739 to 5.79216, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 78ms/step - loss: 5.7922 - accuracy: 0.1009\n",
      "Epoch 4/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 5.3730 - accuracy: 0.1188\n",
      "Epoch 4: loss improved from 5.79216 to 5.37354, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 30s 79ms/step - loss: 5.3735 - accuracy: 0.1189\n",
      "Epoch 5/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 4.9074 - accuracy: 0.1421  \n",
      "Epoch 5: loss improved from 5.37354 to 4.90735, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 26269s 70s/step - loss: 4.9074 - accuracy: 0.1421\n",
      "Epoch 6/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 4.4225 - accuracy: 0.1711\n",
      "Epoch 6: loss improved from 4.90735 to 4.42202, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 16s 42ms/step - loss: 4.4220 - accuracy: 0.1712\n",
      "Epoch 7/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 3.9279 - accuracy: 0.2222\n",
      "Epoch 7: loss improved from 4.42202 to 3.92833, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 52ms/step - loss: 3.9283 - accuracy: 0.2220\n",
      "Epoch 8/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 3.4339 - accuracy: 0.2994\n",
      "Epoch 8: loss improved from 3.92833 to 3.43395, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 3.4339 - accuracy: 0.2994\n",
      "Epoch 9/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 2.9936 - accuracy: 0.3758\n",
      "Epoch 9: loss improved from 3.43395 to 2.99358, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 17s 45ms/step - loss: 2.9936 - accuracy: 0.3758\n",
      "Epoch 10/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 2.5953 - accuracy: 0.4508\n",
      "Epoch 10: loss improved from 2.99358 to 2.59516, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 2.5952 - accuracy: 0.4508\n",
      "Epoch 11/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 2.2644 - accuracy: 0.5191\n",
      "Epoch 11: loss improved from 2.59516 to 2.26436, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 2.2644 - accuracy: 0.5191\n",
      "Epoch 12/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.9826 - accuracy: 0.5861\n",
      "Epoch 12: loss improved from 2.26436 to 1.98256, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 17s 45ms/step - loss: 1.9826 - accuracy: 0.5861\n",
      "Epoch 13/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.7400 - accuracy: 0.6374\n",
      "Epoch 13: loss improved from 1.98256 to 1.73995, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 52ms/step - loss: 1.7399 - accuracy: 0.6374\n",
      "Epoch 14/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.5564 - accuracy: 0.6733\n",
      "Epoch 14: loss improved from 1.73995 to 1.55611, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 53ms/step - loss: 1.5561 - accuracy: 0.6734\n",
      "Epoch 15/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 1.3965 - accuracy: 0.7077\n",
      "Epoch 15: loss improved from 1.55611 to 1.39653, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 17s 45ms/step - loss: 1.3965 - accuracy: 0.7077\n",
      "Epoch 16/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.2573 - accuracy: 0.7378\n",
      "Epoch 16: loss improved from 1.39653 to 1.25721, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 17s 44ms/step - loss: 1.2572 - accuracy: 0.7377\n",
      "Epoch 17/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.1481 - accuracy: 0.7571\n",
      "Epoch 17: loss improved from 1.25721 to 1.14834, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 21s 56ms/step - loss: 1.1483 - accuracy: 0.7570\n",
      "Epoch 18/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 1.0595 - accuracy: 0.7735\n",
      "Epoch 18: loss improved from 1.14834 to 1.05935, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 25s 68ms/step - loss: 1.0593 - accuracy: 0.7736\n",
      "Epoch 19/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.9821 - accuracy: 0.7928\n",
      "Epoch 19: loss improved from 1.05935 to 0.98210, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 16s 43ms/step - loss: 0.9821 - accuracy: 0.7928\n",
      "Epoch 20/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.9231 - accuracy: 0.8010\n",
      "Epoch 20: loss improved from 0.98210 to 0.92332, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.9233 - accuracy: 0.8010\n",
      "Epoch 21/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.8832 - accuracy: 0.8103\n",
      "Epoch 21: loss improved from 0.92332 to 0.88311, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 27s 71ms/step - loss: 0.8831 - accuracy: 0.8104\n",
      "Epoch 22/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.8375 - accuracy: 0.8183\n",
      "Epoch 22: loss improved from 0.88311 to 0.83743, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 24s 63ms/step - loss: 0.8374 - accuracy: 0.8183\n",
      "Epoch 23/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.8253\n",
      "Epoch 23: loss improved from 0.83743 to 0.79509, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 26s 69ms/step - loss: 0.7951 - accuracy: 0.8253\n",
      "Epoch 24/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.8230\n",
      "Epoch 24: loss improved from 0.79509 to 0.77789, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 25s 67ms/step - loss: 0.7779 - accuracy: 0.8230\n",
      "Epoch 25/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7485 - accuracy: 0.8300\n",
      "Epoch 25: loss improved from 0.77789 to 0.74846, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.7485 - accuracy: 0.8300\n",
      "Epoch 26/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7296 - accuracy: 0.8335\n",
      "Epoch 26: loss improved from 0.74846 to 0.72969, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.7297 - accuracy: 0.8334\n",
      "Epoch 27/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7163 - accuracy: 0.8340\n",
      "Epoch 27: loss improved from 0.72969 to 0.71644, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.7164 - accuracy: 0.8340\n",
      "Epoch 28/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.7035 - accuracy: 0.8352\n",
      "Epoch 28: loss improved from 0.71644 to 0.70329, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.7033 - accuracy: 0.8353\n",
      "Epoch 29/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.8409\n",
      "Epoch 29: loss improved from 0.70329 to 0.68847, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.6885 - accuracy: 0.8409\n",
      "Epoch 30/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.8379\n",
      "Epoch 30: loss improved from 0.68847 to 0.67798, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 0.6780 - accuracy: 0.8379\n",
      "Epoch 31/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6634 - accuracy: 0.8413\n",
      "Epoch 31: loss improved from 0.67798 to 0.66371, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 0.6637 - accuracy: 0.8413\n",
      "Epoch 32/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.8416\n",
      "Epoch 32: loss improved from 0.66371 to 0.66127, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 49ms/step - loss: 0.6613 - accuracy: 0.8417\n",
      "Epoch 33/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.8423\n",
      "Epoch 33: loss improved from 0.66127 to 0.65330, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 0.6533 - accuracy: 0.8422\n",
      "Epoch 34/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6460 - accuracy: 0.8435\n",
      "Epoch 34: loss improved from 0.65330 to 0.64574, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.6457 - accuracy: 0.8435\n",
      "Epoch 35/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.8451\n",
      "Epoch 35: loss improved from 0.64574 to 0.64214, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 49ms/step - loss: 0.6421 - accuracy: 0.8451\n",
      "Epoch 36/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.8461\n",
      "Epoch 36: loss improved from 0.64214 to 0.62992, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.6299 - accuracy: 0.8461\n",
      "Epoch 37/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.8462\n",
      "Epoch 37: loss improved from 0.62992 to 0.62364, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 53ms/step - loss: 0.6236 - accuracy: 0.8462\n",
      "Epoch 38/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6243 - accuracy: 0.8454\n",
      "Epoch 38: loss did not improve from 0.62364\n",
      "377/377 [==============================] - 19s 49ms/step - loss: 0.6240 - accuracy: 0.8455\n",
      "Epoch 39/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6194 - accuracy: 0.8452\n",
      "Epoch 39: loss improved from 0.62364 to 0.61938, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 0.6194 - accuracy: 0.8452\n",
      "Epoch 40/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.8457\n",
      "Epoch 40: loss did not improve from 0.61938\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6199 - accuracy: 0.8457\n",
      "Epoch 41/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.8477\n",
      "Epoch 41: loss improved from 0.61938 to 0.61152, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6115 - accuracy: 0.8477\n",
      "Epoch 42/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6043 - accuracy: 0.8477\n",
      "Epoch 42: loss improved from 0.61152 to 0.60425, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6042 - accuracy: 0.8476\n",
      "Epoch 43/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6071 - accuracy: 0.8463\n",
      "Epoch 43: loss did not improve from 0.60425\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6068 - accuracy: 0.8464\n",
      "Epoch 44/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.8453\n",
      "Epoch 44: loss did not improve from 0.60425\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6113 - accuracy: 0.8453\n",
      "Epoch 45/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6091 - accuracy: 0.8460\n",
      "Epoch 45: loss did not improve from 0.60425\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.6095 - accuracy: 0.8459\n",
      "Epoch 46/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.6029 - accuracy: 0.8474\n",
      "Epoch 46: loss improved from 0.60425 to 0.60257, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 49ms/step - loss: 0.6026 - accuracy: 0.8475\n",
      "Epoch 47/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.8486\n",
      "Epoch 47: loss improved from 0.60257 to 0.59837, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.5984 - accuracy: 0.8486\n",
      "Epoch 48/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5947 - accuracy: 0.8489\n",
      "Epoch 48: loss improved from 0.59837 to 0.59446, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 18s 48ms/step - loss: 0.5945 - accuracy: 0.8490\n",
      "Epoch 49/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.8486\n",
      "Epoch 49: loss did not improve from 0.59446\n",
      "377/377 [==============================] - 18s 47ms/step - loss: 0.5981 - accuracy: 0.8486\n",
      "Epoch 50/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5903 - accuracy: 0.8484\n",
      "Epoch 50: loss improved from 0.59446 to 0.59004, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5900 - accuracy: 0.8485\n",
      "Epoch 51/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.8483\n",
      "Epoch 51: loss improved from 0.59004 to 0.58814, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5881 - accuracy: 0.8484\n",
      "Epoch 52/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5844 - accuracy: 0.8499\n",
      "Epoch 52: loss improved from 0.58814 to 0.58425, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 22s 57ms/step - loss: 0.5843 - accuracy: 0.8500\n",
      "Epoch 53/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5837 - accuracy: 0.8501\n",
      "Epoch 53: loss improved from 0.58425 to 0.58349, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 23s 61ms/step - loss: 0.5835 - accuracy: 0.8501\n",
      "Epoch 54/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.8482\n",
      "Epoch 54: loss did not improve from 0.58349\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.5922 - accuracy: 0.8482\n",
      "Epoch 55/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.8487\n",
      "Epoch 55: loss improved from 0.58349 to 0.58042, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.5804 - accuracy: 0.8487\n",
      "Epoch 56/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8511\n",
      "Epoch 56: loss improved from 0.58042 to 0.57962, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 52ms/step - loss: 0.5796 - accuracy: 0.8511\n",
      "Epoch 57/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5733 - accuracy: 0.8492\n",
      "Epoch 57: loss improved from 0.57962 to 0.57301, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5730 - accuracy: 0.8492\n",
      "Epoch 58/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.8501\n",
      "Epoch 58: loss did not improve from 0.57301\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.5801 - accuracy: 0.8501\n",
      "Epoch 59/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5758 - accuracy: 0.8492\n",
      "Epoch 59: loss did not improve from 0.57301\n",
      "377/377 [==============================] - 18s 49ms/step - loss: 0.5756 - accuracy: 0.8493\n",
      "Epoch 60/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.8501\n",
      "Epoch 60: loss improved from 0.57301 to 0.57225, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 50ms/step - loss: 0.5722 - accuracy: 0.8501\n",
      "Epoch 61/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.8516\n",
      "Epoch 61: loss improved from 0.57225 to 0.57063, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 52ms/step - loss: 0.5706 - accuracy: 0.8516\n",
      "Epoch 62/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8507\n",
      "Epoch 62: loss did not improve from 0.57063\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.5719 - accuracy: 0.8507\n",
      "Epoch 63/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5670 - accuracy: 0.8504\n",
      "Epoch 63: loss improved from 0.57063 to 0.56672, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5667 - accuracy: 0.8505\n",
      "Epoch 64/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5648 - accuracy: 0.8514\n",
      "Epoch 64: loss improved from 0.56672 to 0.56510, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5651 - accuracy: 0.8513\n",
      "Epoch 65/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.8510\n",
      "Epoch 65: loss did not improve from 0.56510\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.5659 - accuracy: 0.8510\n",
      "Epoch 66/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.8502\n",
      "Epoch 66: loss did not improve from 0.56510\n",
      "377/377 [==============================] - 21s 57ms/step - loss: 0.5713 - accuracy: 0.8502\n",
      "Epoch 67/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.8504\n",
      "Epoch 67: loss did not improve from 0.56510\n",
      "377/377 [==============================] - 21s 57ms/step - loss: 0.5670 - accuracy: 0.8505\n",
      "Epoch 68/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5671 - accuracy: 0.8508\n",
      "Epoch 68: loss did not improve from 0.56510\n",
      "377/377 [==============================] - 21s 57ms/step - loss: 0.5677 - accuracy: 0.8506\n",
      "Epoch 69/1000\n",
      "377/377 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8511\n",
      "Epoch 69: loss improved from 0.56510 to 0.56430, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 21s 55ms/step - loss: 0.5643 - accuracy: 0.8511\n",
      "Epoch 70/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5668 - accuracy: 0.8520\n",
      "Epoch 70: loss did not improve from 0.56430\n",
      "377/377 [==============================] - 22s 58ms/step - loss: 0.5669 - accuracy: 0.8520\n",
      "Epoch 71/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8501\n",
      "Epoch 71: loss improved from 0.56430 to 0.56173, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 26s 70ms/step - loss: 0.5617 - accuracy: 0.8502\n",
      "Epoch 72/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5582 - accuracy: 0.8523\n",
      "Epoch 72: loss improved from 0.56173 to 0.55860, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 22s 58ms/step - loss: 0.5586 - accuracy: 0.8522\n",
      "Epoch 73/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8508\n",
      "Epoch 73: loss did not improve from 0.55860\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.5618 - accuracy: 0.8509\n",
      "Epoch 74/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.8518\n",
      "Epoch 74: loss did not improve from 0.55860\n",
      "377/377 [==============================] - 20s 53ms/step - loss: 0.5591 - accuracy: 0.8517\n",
      "Epoch 75/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.8534\n",
      "Epoch 75: loss improved from 0.55860 to 0.55359, saving model to gru_model_checkpoint.h5\n",
      "377/377 [==============================] - 20s 53ms/step - loss: 0.5536 - accuracy: 0.8534\n",
      "Epoch 76/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5565 - accuracy: 0.8520\n",
      "Epoch 76: loss did not improve from 0.55359\n",
      "377/377 [==============================] - 22s 59ms/step - loss: 0.5564 - accuracy: 0.8520\n",
      "Epoch 77/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5622 - accuracy: 0.8492\n",
      "Epoch 77: loss did not improve from 0.55359\n",
      "377/377 [==============================] - 20s 54ms/step - loss: 0.5625 - accuracy: 0.8491\n",
      "Epoch 78/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5582 - accuracy: 0.8501\n",
      "Epoch 78: loss did not improve from 0.55359\n",
      "377/377 [==============================] - 19s 52ms/step - loss: 0.5580 - accuracy: 0.8501\n",
      "Epoch 79/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5565 - accuracy: 0.8493\n",
      "Epoch 79: loss did not improve from 0.55359\n",
      "377/377 [==============================] - 20s 52ms/step - loss: 0.5563 - accuracy: 0.8494\n",
      "Epoch 80/1000\n",
      "376/377 [============================>.] - ETA: 0s - loss: 0.5560 - accuracy: 0.8511Restoring model weights from the end of the best epoch: 75.\n",
      "\n",
      "Epoch 80: loss did not improve from 0.55359\n",
      "377/377 [==============================] - 19s 51ms/step - loss: 0.5561 - accuracy: 0.8511\n",
      "Epoch 80: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(total_words, 100, input_length=max_sequences_len-1))\n",
    "gru_model.add(GRU(256))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(learning_rate=0.001)\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "gru_model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"gru_model_checkpoint.h5\",\n",
    "                             monitor=\"loss\",\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode=\"min\")\n",
    "\n",
    "gru_history = gru_model.fit(xs, ys, epochs=1000, verbose=1, callbacks=[earlystop, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(gru_history,string):\n",
    "    plt.plot (gru_history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(gru_history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 725ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "I've got a good feeling about this across the rocky road to dublin the follol de rah fell on the bright tree to fulfill youll see my\n"
     ]
    }
   ],
   "source": [
    "seed_text= \"I've got a good feeling about this\"\n",
    "next_words = 20\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequences_len - 1, padding='pre')\n",
    "    predicted = np.argmax(gru_model.predict(token_list), axis=1)\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model checkpoints\n",
    "model_checkpoint_1 = load_model(\"model_checkpoint.h5\")\n",
    "lstm_model_checkpoint = load_model(\"lstm_model_checkpoint.h5\")\n",
    "gru_model_checkpoint = load_model(\"gru_model_checkpoint.h5\")\n",
    "\n",
    "# Dump the model checkpoints using pickle\n",
    "with open(\"model_checkpoint_1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_checkpoint_1, f)\n",
    "\n",
    "with open(\"lstm_model_checkpoint.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lstm_model_checkpoint, f)\n",
    "\n",
    "with open(\"gru_model_checkpoint.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gru_model_checkpoint, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
